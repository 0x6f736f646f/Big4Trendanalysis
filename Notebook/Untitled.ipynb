{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, nltk\n",
    "import pickle\n",
    "from scipy.stats import mode\n",
    "from statistics import mean\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify import ClassifierI\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.classify import DecisionTreeClassifier, ConditionalExponentialClassifier, MaxentClassifier, NaiveBayesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "import xgboost\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    def classify(self, features):\n",
    "        votes =[]\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return str(mode(votes)[0])\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes =[]\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = int(mode(votes)[1])\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pos = open(\"../Data/positive-words.txt\", \"r\").read()\n",
    "short_neg = open(\"../Data/negative-words.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pos_words = word_tokenize(short_pos.lower())\n",
    "short_neg_words = word_tokenize(short_neg.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accessable'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_pos_words[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(words, True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "negfeats = [(word_feats(f), 'neg') for f in short_neg_words]\n",
    "posfeats = [(word_feats(f), 'pos') for f in short_pos_words]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accessible': True}, 'pos')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posfeats[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = negfeats + posfeats\n",
    "for i in range(0,1000,1):\n",
    "    random.shuffle(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6791"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = int((2*len(features))/3)\n",
    "training_set = features[:m]\n",
    "testing_set = features[m:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'phenomenally': True}, 'pos')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7031802120141343\n",
      "Most Informative Features\n",
      "                 envious = True              pos : neg    =      2.4 : 1.0\n",
      "               resilient = None              neg : pos    =      1.0 : 1.0\n",
      "             affectation = None              neg : pos    =      1.0 : 1.0\n",
      "                  appeal = None              neg : pos    =      1.0 : 1.0\n",
      "              impressive = None              neg : pos    =      1.0 : 1.0\n",
      "                sturdier = None              neg : pos    =      1.0 : 1.0\n",
      "               nurturing = None              neg : pos    =      1.0 : 1.0\n",
      "              fearlessly = None              neg : pos    =      1.0 : 1.0\n",
      "               enrapture = None              neg : pos    =      1.0 : 1.0\n",
      "                 respite = None              neg : pos    =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_set)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testing_set))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algo accuracy[%]:  70.31802120141343\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Naive Bayes Algo accuracy[%]: \", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "x1 = (nltk.classify.accuracy(classifier, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Naive Bayes Algo accuracy[%]:  70.31802120141343\n"
     ]
    }
   ],
   "source": [
    "MNB = SklearnClassifier(MultinomialNB())\n",
    "MNB.train(training_set)\n",
    "print(\"MultinomialNB Naive Bayes Algo accuracy[%]: \", (nltk.classify.accuracy(MNB, testing_set))*100)\n",
    "x2 = (nltk.classify.accuracy(MNB, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Naive Bayes Algo accuracy[%]:  70.36219081272085\n"
     ]
    }
   ],
   "source": [
    "BNB = SklearnClassifier(BernoulliNB())\n",
    "BNB.train(training_set)\n",
    "print(\"BernoulliNB Naive Bayes Algo accuracy[%]: \", (nltk.classify.accuracy(BNB, testing_set))*100)\n",
    "x3 = (nltk.classify.accuracy(BNB, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Algo accuracy[%]:  70.36219081272085\n"
     ]
    }
   ],
   "source": [
    "LR = SklearnClassifier(LogisticRegression())\n",
    "LR.train(training_set)\n",
    "print(\"LogisticRegression Algo accuracy[%]: \", (nltk.classify.accuracy(LR, testing_set))*100)\n",
    "x4 = (nltk.classify.accuracy(LR, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SGDClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-40b8424ecdbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSGD_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSklearnClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mSGD_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SGDClassifier Algo accuracy[%]: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SGDClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "SGD_1 = SklearnClassifier(SGDClassifier())\n",
    "SGD_1.train(training_set)\n",
    "print(\"SGDClassifier Algo accuracy[%]: \", (nltk.classify.accuracy(SGD_1, testing_set))*100)\n",
    "x5 = (nltk.classify.accuracy(SGD_1, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Algo accuracy[%]:  70.31802120141343\n"
     ]
    }
   ],
   "source": [
    "LSVC_1 = SklearnClassifier(LinearSVC())\n",
    "LSVC_1.train(training_set)\n",
    "print(\"Linear SVC Algo accuracy[%]: \", (nltk.classify.accuracy(LSVC_1, testing_set))*100)\n",
    "x6 = (nltk.classify.accuracy(LSVC_1, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC Algo accuracy[%]:  70.31802120141343\n"
     ]
    }
   ],
   "source": [
    "NSVC_1 = SklearnClassifier(NuSVC())\n",
    "NSVC_1.train(training_set)\n",
    "print(\"NuSVC Algo accuracy[%]: \", (nltk.classify.accuracy(NSVC_1, testing_set))*100)\n",
    "x7 = (nltk.classify.accuracy(NSVC_1, testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algo accuracy[%]:  70.31802120141343\n",
      "Most Informative Features\n",
      "                 envious = True              pos : neg    =      2.4 : 1.0\n",
      "               resilient = None              neg : pos    =      1.0 : 1.0\n",
      "             affectation = None              neg : pos    =      1.0 : 1.0\n",
      "                  appeal = None              neg : pos    =      1.0 : 1.0\n",
      "              impressive = None              neg : pos    =      1.0 : 1.0\n",
      "                sturdier = None              neg : pos    =      1.0 : 1.0\n",
      "               nurturing = None              neg : pos    =      1.0 : 1.0\n",
      "              fearlessly = None              neg : pos    =      1.0 : 1.0\n",
      "               enrapture = None              neg : pos    =      1.0 : 1.0\n",
      "                 respite = None              neg : pos    =      1.0 : 1.0\n",
      "          problem-solver = None              neg : pos    =      1.0 : 1.0\n",
      "               effectual = None              neg : pos    =      1.0 : 1.0\n",
      "                 dead-on = None              neg : pos    =      1.0 : 1.0\n",
      "               desirable = None              neg : pos    =      1.0 : 1.0\n",
      "                endorses = None              neg : pos    =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Naive Bayes Algo accuracy[%]: \", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.4\n",
      "Negative: 0.6\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "sentence = \"Awesome movie, I liked it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    " \n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
